"""
Quantitative Analysis and Backtesting Tools for Financial Analysis MCP Server
Provides backtesting, portfolio optimization, and quantitative strategies
"""
import json
from typing import Optional, List, Dict, Any, Tuple
from datetime import datetime, timedelta
import yfinance as yf
import pandas as pd
import numpy as np

# ============================================================================
# BACKTESTING TOOLS
# ============================================================================

async def backtest_strategy(
    ticker: str,
    strategy: str,
    start_date: str,
    end_date: str,
    initial_capital: float = 10000.0,
    parameters: Dict = None
) -> str:
    """
    Backtest a trading strategy on historical data.
    
    Args:
        ticker: Ticker symbol
        strategy: Strategy name (sma_crossover, rsi, bollinger, buy_and_hold)
        start_date: Start date in YYYY-MM-DD format
        end_date: End date in YYYY-MM-DD format
        initial_capital: Initial investment amount
        parameters: Strategy-specific parameters
    
    Returns:
        JSON string with backtest results including returns, trades, and metrics
    """
    try:
        # Fetch historical data
        ticker_obj = yf.Ticker(ticker)
        data = ticker_obj.history(start=start_date, end=end_date)
        
        if data.empty:
            return json.dumps({"error": f"No data available for {ticker}"})
        
        # Initialize results
        results = {
            "ticker": ticker,
            "strategy": strategy,
            "period": f"{start_date} to {end_date}",
            "initial_capital": initial_capital,
            "parameters": parameters or {}
        }
        
        # Run strategy
        if strategy == "sma_crossover":
            trades, metrics = backtest_sma_crossover(data, initial_capital, parameters)
        elif strategy == "rsi":
            trades, metrics = backtest_rsi_strategy(data, initial_capital, parameters)
        elif strategy == "bollinger":
            trades, metrics = backtest_bollinger_bands(data, initial_capital, parameters)
        elif strategy == "buy_and_hold":
            trades, metrics = backtest_buy_and_hold(data, initial_capital)
        else:
            return json.dumps({"error": f"Unknown strategy: {strategy}"})
        
        results["trades"] = trades
        results["metrics"] = metrics
        
        # Calculate performance metrics
        results["performance"] = calculate_performance_metrics(metrics)
        
        return json.dumps(results, indent=2, default=str)
        
    except Exception as e:
        return json.dumps({"error": str(e)})

def backtest_sma_crossover(
    data: pd.DataFrame,
    initial_capital: float,
    parameters: Dict = None
) -> Tuple[List[Dict], Dict]:
    """Backtest SMA crossover strategy."""
    params = parameters or {}
    fast_period = params.get("fast_period", 10)
    slow_period = params.get("slow_period", 30)
    
    # Calculate SMAs
    data['SMA_fast'] = data['Close'].rolling(window=fast_period).mean()
    data['SMA_slow'] = data['Close'].rolling(window=slow_period).mean()
    
    # Generate signals
    data['Signal'] = 0
    data.loc[data['SMA_fast'] > data['SMA_slow'], 'Signal'] = 1
    data.loc[data['SMA_fast'] < data['SMA_slow'], 'Signal'] = -1
    
    # Execute trades
    trades = []
    position = 0
    capital = initial_capital
    shares = 0
    
    for i in range(1, len(data)):
        if data['Signal'].iloc[i] == 1 and position <= 0:
            # Buy signal
            shares = capital / data['Close'].iloc[i]
            trades.append({
                "date": data.index[i].strftime("%Y-%m-%d"),
                "type": "BUY",
                "price": float(data['Close'].iloc[i]),
                "shares": float(shares),
                "value": float(capital)
            })
            position = 1
            
        elif data['Signal'].iloc[i] == -1 and position >= 0:
            # Sell signal
            if shares > 0:
                capital = shares * data['Close'].iloc[i]
                trades.append({
                    "date": data.index[i].strftime("%Y-%m-%d"),
                    "type": "SELL",
                    "price": float(data['Close'].iloc[i]),
                    "shares": float(shares),
                    "value": float(capital)
                })
                shares = 0
            position = -1
    
    # Final value
    if shares > 0:
        capital = shares * data['Close'].iloc[-1]
    
    metrics = {
        "final_capital": float(capital),
        "total_return": float((capital - initial_capital) / initial_capital * 100),
        "number_of_trades": len(trades)
    }
    
    return trades[:10], metrics  # Return only first 10 trades for brevity

def backtest_rsi_strategy(
    data: pd.DataFrame,
    initial_capital: float,
    parameters: Dict = None
) -> Tuple[List[Dict], Dict]:
    """Backtest RSI strategy."""
    params = parameters or {}
    rsi_period = params.get("period", 14)
    oversold = params.get("oversold", 30)
    overbought = params.get("overbought", 70)
    
    # Calculate RSI
    delta = data['Close'].diff()
    gain = (delta.where(delta > 0, 0)).rolling(window=rsi_period).mean()
    loss = (-delta.where(delta < 0, 0)).rolling(window=rsi_period).mean()
    rs = gain / loss
    data['RSI'] = 100 - (100 / (1 + rs))
    
    # Generate signals
    trades = []
    position = 0
    capital = initial_capital
    shares = 0
    
    for i in range(rsi_period, len(data)):
        if data['RSI'].iloc[i] < oversold and position == 0:
            # Buy signal (oversold)
            shares = capital / data['Close'].iloc[i]
            trades.append({
                "date": data.index[i].strftime("%Y-%m-%d"),
                "type": "BUY",
                "price": float(data['Close'].iloc[i]),
                "rsi": float(data['RSI'].iloc[i])
            })
            position = 1
            
        elif data['RSI'].iloc[i] > overbought and position == 1:
            # Sell signal (overbought)
            capital = shares * data['Close'].iloc[i]
            trades.append({
                "date": data.index[i].strftime("%Y-%m-%d"),
                "type": "SELL",
                "price": float(data['Close'].iloc[i]),
                "rsi": float(data['RSI'].iloc[i])
            })
            shares = 0
            position = 0
    
    # Final value
    if shares > 0:
        capital = shares * data['Close'].iloc[-1]
    
    metrics = {
        "final_capital": float(capital),
        "total_return": float((capital - initial_capital) / initial_capital * 100),
        "number_of_trades": len(trades)
    }
    
    return trades[:10], metrics

def backtest_bollinger_bands(
    data: pd.DataFrame,
    initial_capital: float,
    parameters: Dict = None
) -> Tuple[List[Dict], Dict]:
    """Backtest Bollinger Bands strategy."""
    params = parameters or {}
    period = params.get("period", 20)
    std_dev = params.get("std_dev", 2)
    
    # Calculate Bollinger Bands
    data['BB_middle'] = data['Close'].rolling(window=period).mean()
    bb_std = data['Close'].rolling(window=period).std()
    data['BB_upper'] = data['BB_middle'] + (bb_std * std_dev)
    data['BB_lower'] = data['BB_middle'] - (bb_std * std_dev)
    
    # Generate signals
    trades = []
    position = 0
    capital = initial_capital
    shares = 0
    
    for i in range(period, len(data)):
        if data['Close'].iloc[i] < data['BB_lower'].iloc[i] and position == 0:
            # Buy signal (price below lower band)
            shares = capital / data['Close'].iloc[i]
            trades.append({
                "date": data.index[i].strftime("%Y-%m-%d"),
                "type": "BUY",
                "price": float(data['Close'].iloc[i]),
                "signal": "Below lower band"
            })
            position = 1
            
        elif data['Close'].iloc[i] > data['BB_upper'].iloc[i] and position == 1:
            # Sell signal (price above upper band)
            capital = shares * data['Close'].iloc[i]
            trades.append({
                "date": data.index[i].strftime("%Y-%m-%d"),
                "type": "SELL",
                "price": float(data['Close'].iloc[i]),
                "signal": "Above upper band"
            })
            shares = 0
            position = 0
    
    # Final value
    if shares > 0:
        capital = shares * data['Close'].iloc[-1]
    
    metrics = {
        "final_capital": float(capital),
        "total_return": float((capital - initial_capital) / initial_capital * 100),
        "number_of_trades": len(trades)
    }
    
    return trades[:10], metrics

def backtest_buy_and_hold(
    data: pd.DataFrame,
    initial_capital: float
) -> Tuple[List[Dict], Dict]:
    """Backtest buy and hold strategy."""
    # Simple buy and hold
    shares = initial_capital / data['Close'].iloc[0]
    final_capital = shares * data['Close'].iloc[-1]
    
    trades = [{
        "date": data.index[0].strftime("%Y-%m-%d"),
        "type": "BUY",
        "price": float(data['Close'].iloc[0]),
        "shares": float(shares)
    }]
    
    metrics = {
        "final_capital": float(final_capital),
        "total_return": float((final_capital - initial_capital) / initial_capital * 100),
        "number_of_trades": 1
    }
    
    return trades, metrics

def calculate_performance_metrics(metrics: Dict) -> Dict:
    """Calculate additional performance metrics."""
    performance = {}
    
    # Basic metrics
    performance["total_return_pct"] = metrics.get("total_return", 0)
    performance["final_value"] = metrics.get("final_capital", 0)
    
    # Win rate (if we have trade details)
    if "winning_trades" in metrics and "total_trades" in metrics:
        if metrics["total_trades"] > 0:
            performance["win_rate"] = metrics["winning_trades"] / metrics["total_trades"] * 100
    
    # Risk metrics would require more detailed trade data
    performance["max_drawdown"] = metrics.get("max_drawdown", "N/A")
    performance["sharpe_ratio"] = metrics.get("sharpe_ratio", "N/A")
    
    return performance

# ============================================================================
# PORTFOLIO OPTIMIZATION
# ============================================================================

async def optimize_portfolio(
    tickers: List[str],
    start_date: str,
    end_date: str,
    optimization_method: str = "equal_weight"
) -> str:
    """
    Optimize portfolio allocation across multiple assets.
    
    Args:
        tickers: List of ticker symbols
        start_date: Start date for historical data
        end_date: End date for historical data
        optimization_method: Method for optimization (equal_weight, min_variance, max_sharpe)
    
    Returns:
        JSON string with optimal weights and expected performance
    """
    try:
        # Fetch data for all tickers
        data = {}
        for ticker in tickers:
            ticker_obj = yf.Ticker(ticker)
            hist = ticker_obj.history(start=start_date, end=end_date)
            if not hist.empty:
                data[ticker] = hist['Close']
        
        if not data:
            return json.dumps({"error": "No data available for tickers"})
        
        # Create price dataframe
        prices = pd.DataFrame(data)
        returns = prices.pct_change().dropna()
        
        # Calculate weights based on method
        if optimization_method == "equal_weight":
            weights = equal_weight_portfolio(tickers)
        elif optimization_method == "min_variance":
            weights = min_variance_portfolio(returns)
        elif optimization_method == "max_sharpe":
            weights = max_sharpe_portfolio(returns)
        else:
            weights = equal_weight_portfolio(tickers)
        
        # Calculate portfolio metrics
        portfolio_return = calculate_portfolio_return(returns, weights)
        portfolio_volatility = calculate_portfolio_volatility(returns, weights)
        sharpe_ratio = portfolio_return / portfolio_volatility if portfolio_volatility > 0 else 0
        
        result = {
            "tickers": tickers,
            "optimization_method": optimization_method,
            "weights": {ticker: float(weight) for ticker, weight in zip(tickers, weights)},
            "expected_annual_return": float(portfolio_return * 252),  # Annualized
            "expected_volatility": float(portfolio_volatility * np.sqrt(252)),  # Annualized
            "sharpe_ratio": float(sharpe_ratio * np.sqrt(252)),  # Annualized
            "period": f"{start_date} to {end_date}"
        }
        
        return json.dumps(result, indent=2)
        
    except Exception as e:
        return json.dumps({"error": str(e)})

def equal_weight_portfolio(tickers: List[str]) -> np.ndarray:
    """Create equal weight portfolio."""
    n = len(tickers)
    return np.array([1/n] * n)

def min_variance_portfolio(returns: pd.DataFrame) -> np.ndarray:
    """Calculate minimum variance portfolio weights."""
    # Calculate covariance matrix
    cov_matrix = returns.cov()
    n = len(returns.columns)
    
    # Simple equal weight for now (full optimization would require scipy.optimize)
    # In production, would use quadratic programming to minimize variance
    return np.array([1/n] * n)

def max_sharpe_portfolio(returns: pd.DataFrame) -> np.ndarray:
    """Calculate maximum Sharpe ratio portfolio weights."""
    # This would require optimization library
    # For simplicity, using equal weights
    n = len(returns.columns)
    return np.array([1/n] * n)

def calculate_portfolio_return(returns: pd.DataFrame, weights: np.ndarray) -> float:
    """Calculate expected portfolio return."""
    return np.dot(returns.mean(), weights)

def calculate_portfolio_volatility(returns: pd.DataFrame, weights: np.ndarray) -> float:
    """Calculate portfolio volatility."""
    cov_matrix = returns.cov()
    portfolio_variance = np.dot(weights, np.dot(cov_matrix, weights))
    return np.sqrt(portfolio_variance)

# ============================================================================
# RISK ANALYSIS
# ============================================================================

async def calculate_var(
    ticker: str,
    confidence_level: float = 0.95,
    time_horizon: int = 1,
    lookback_days: int = 252
) -> str:
    """
    Calculate Value at Risk (VaR) for a position.
    
    Args:
        ticker: Ticker symbol
        confidence_level: Confidence level (e.g., 0.95 for 95%)
        time_horizon: Time horizon in days
        lookback_days: Historical data period in days
    
    Returns:
        JSON string with VaR calculations
    """
    try:
        # Fetch historical data
        end_date = datetime.now()
        start_date = end_date - timedelta(days=lookback_days)
        
        ticker_obj = yf.Ticker(ticker)
        data = ticker_obj.history(start=start_date.strftime("%Y-%m-%d"), end=end_date.strftime("%Y-%m-%d"))
        
        if data.empty:
            return json.dumps({"error": f"No data available for {ticker}"})
        
        # Calculate returns
        returns = data['Close'].pct_change().dropna()
        
        # Historical VaR
        var_percentile = (1 - confidence_level) * 100
        historical_var = np.percentile(returns, var_percentile)
        
        # Parametric VaR (assuming normal distribution)
        mean_return = returns.mean()
        std_return = returns.std()
        from scipy import stats
        z_score = stats.norm.ppf(1 - confidence_level)
        parametric_var = mean_return + z_score * std_return
        
        # Scale to time horizon
        historical_var_scaled = historical_var * np.sqrt(time_horizon)
        parametric_var_scaled = parametric_var * np.sqrt(time_horizon)
        
        result = {
            "ticker": ticker,
            "confidence_level": confidence_level,
            "time_horizon_days": time_horizon,
            "lookback_days": lookback_days,
            "var_historical": {
                "daily": float(historical_var * 100),
                "scaled": float(historical_var_scaled * 100),
                "interpretation": f"With {confidence_level*100}% confidence, daily loss won't exceed {abs(historical_var)*100:.2f}%"
            },
            "var_parametric": {
                "daily": float(parametric_var * 100),
                "scaled": float(parametric_var_scaled * 100),
                "interpretation": f"Assuming normal distribution, daily loss won't exceed {abs(parametric_var)*100:.2f}%"
            },
            "current_price": float(data['Close'].iloc[-1]),
            "dollar_var_per_share": float(abs(historical_var) * data['Close'].iloc[-1])
        }
        
        return json.dumps(result, indent=2)
        
    except Exception as e:
        return json.dumps({"error": str(e)})

async def calculate_beta(
    ticker: str,
    market_ticker: str = "SPY",
    lookback_days: int = 252
) -> str:
    """
    Calculate beta relative to market index.
    
    Args:
        ticker: Ticker symbol
        market_ticker: Market index ticker (default: SPY)
        lookback_days: Historical data period
    
    Returns:
        JSON string with beta calculation and interpretation
    """
    try:
        end_date = datetime.now()
        start_date = end_date - timedelta(days=lookback_days)
        
        # Fetch data
        stock = yf.Ticker(ticker)
        market = yf.Ticker(market_ticker)
        
        stock_data = stock.history(start=start_date.strftime("%Y-%m-%d"), end=end_date.strftime("%Y-%m-%d"))
        market_data = market.history(start=start_date.strftime("%Y-%m-%d"), end=end_date.strftime("%Y-%m-%d"))
        
        if stock_data.empty or market_data.empty:
            return json.dumps({"error": "Insufficient data for beta calculation"})
        
        # Calculate returns
        stock_returns = stock_data['Close'].pct_change().dropna()
        market_returns = market_data['Close'].pct_change().dropna()
        
        # Align the data
        aligned_data = pd.DataFrame({
            'stock': stock_returns,
            'market': market_returns
        }).dropna()
        
        # Calculate beta
        covariance = aligned_data['stock'].cov(aligned_data['market'])
        market_variance = aligned_data['market'].var()
        beta = covariance / market_variance if market_variance != 0 else 0
        
        # Calculate correlation
        correlation = aligned_data['stock'].corr(aligned_data['market'])
        
        # Interpretation
        if beta > 1.5:
            interpretation = "High beta - significantly more volatile than market"
        elif beta > 1:
            interpretation = "Above market volatility"
        elif beta > 0.5:
            interpretation = "Below market volatility - defensive stock"
        else:
            interpretation = "Low beta - minimal correlation with market"
        
        result = {
            "ticker": ticker,
            "market_index": market_ticker,
            "beta": float(beta),
            "correlation": float(correlation),
            "lookback_days": lookback_days,
            "interpretation": interpretation,
            "risk_profile": "Aggressive" if beta > 1.2 else "Moderate" if beta > 0.8 else "Conservative"
        }
        
        return json.dumps(result, indent=2)
        
    except Exception as e:
        return json.dumps({"error": str(e)})

# ============================================================================
# TECHNICAL ANALYSIS
# ============================================================================

async def identify_chart_patterns(
    ticker: str,
    lookback_days: int = 90
) -> str:
    """
    Identify common chart patterns in price data.
    
    Args:
        ticker: Ticker symbol
        lookback_days: Period to analyze
    
    Returns:
        JSON string with identified patterns
    """
    try:
        end_date = datetime.now()
        start_date = end_date - timedelta(days=lookback_days)
        
        ticker_obj = yf.Ticker(ticker)
        data = ticker_obj.history(start=start_date.strftime("%Y-%m-%d"), end=end_date.strftime("%Y-%m-%d"))
        
        if data.empty:
            return json.dumps({"error": f"No data available for {ticker}"})
        
        patterns = {
            "ticker": ticker,
            "period": f"{lookback_days} days",
            "identified_patterns": []
        }
        
        # Support and Resistance
        support, resistance = identify_support_resistance(data)
        if support or resistance:
            patterns["identified_patterns"].append({
                "pattern": "Support/Resistance",
                "support_levels": support,
                "resistance_levels": resistance
            })
        
        # Trend
        trend = identify_trend(data)
        patterns["identified_patterns"].append({
            "pattern": "Trend",
            "direction": trend["direction"],
            "strength": trend["strength"]
        })
        
        # Moving average crossovers
        ma_signals = check_ma_crossovers(data)
        if ma_signals:
            patterns["identified_patterns"].append({
                "pattern": "MA Crossover",
                "signals": ma_signals
            })
        
        # Current position
        patterns["current_price"] = float(data['Close'].iloc[-1])
        patterns["price_change_pct"] = float((data['Close'].iloc[-1] - data['Close'].iloc[0]) / data['Close'].iloc[0] * 100)
        
        return json.dumps(patterns, indent=2, default=str)
        
    except Exception as e:
        return json.dumps({"error": str(e)})

def identify_support_resistance(data: pd.DataFrame) -> Tuple[List[float], List[float]]:
    """Identify support and resistance levels."""
    # Simple implementation: use recent highs and lows
    highs = data['High'].rolling(window=20).max()
    lows = data['Low'].rolling(window=20).min()
    
    # Get unique levels
    resistance_levels = sorted(set(highs.dropna().round(2).tolist()))[-3:]  # Top 3
    support_levels = sorted(set(lows.dropna().round(2).tolist()))[:3]  # Bottom 3
    
    return support_levels, resistance_levels

def identify_trend(data: pd.DataFrame) -> Dict:
    """Identify price trend."""
    # Simple trend identification using linear regression
    prices = data['Close'].values
    x = np.arange(len(prices))
    
    # Calculate slope
    slope = np.polyfit(x, prices, 1)[0]
    
    # Determine trend
    if slope > 0:
        direction = "Uptrend"
        strength = "Strong" if slope > prices[0] * 0.001 else "Weak"
    elif slope < 0:
        direction = "Downtrend"
        strength = "Strong" if abs(slope) > prices[0] * 0.001 else "Weak"
    else:
        direction = "Sideways"
        strength = "Neutral"
    
    return {"direction": direction, "strength": strength}

def check_ma_crossovers(data: pd.DataFrame) -> List[Dict]:
    """Check for moving average crossovers."""
    signals = []
    
    # Calculate MAs
    data['MA_20'] = data['Close'].rolling(window=20).mean()
    data['MA_50'] = data['Close'].rolling(window=50).mean()
    
    # Check recent crossover
    if len(data) >= 50:
        recent = data.tail(5)
        if recent['MA_20'].iloc[-1] > recent['MA_50'].iloc[-1] and recent['MA_20'].iloc[0] <= recent['MA_50'].iloc[0]:
            signals.append({
                "type": "Golden Cross",
                "signal": "Bullish",
                "date": recent.index[-1].strftime("%Y-%m-%d")
            })
        elif recent['MA_20'].iloc[-1] < recent['MA_50'].iloc[-1] and recent['MA_20'].iloc[0] >= recent['MA_50'].iloc[0]:
            signals.append({
                "type": "Death Cross",
                "signal": "Bearish",
                "date": recent.index[-1].strftime("%Y-%m-%d")
            })
    
    return signals
